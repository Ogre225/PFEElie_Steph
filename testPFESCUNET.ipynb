{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETZ8wGuMIpJZ",
        "outputId": "b4f64a2b-1b73-4274-aeae-302051a4f977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from thop import profile\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from timm.models.layers import trunc_normal_, DropPath\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFh0RmKMJBbj",
        "outputId": "56e19dc5-59f4-4982-8e36-3d39013aa428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install thop"
      ],
      "metadata": {
        "id": "075LIZCMwB-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "id": "g_wac4ZxwEsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppWtTUDNwKqu",
        "outputId": "2c43124e-9214-47c0-8203-ece92c9040c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jYSYcNbgG4kB"
      },
      "outputs": [],
      "source": [
        "###Fonction pour telecharger BSD400 en zip\n",
        "####Si elle ne parche pas, copier le lien et download le zip puis le poser dans le repertooire\n",
        "\n",
        "\n",
        "def download_dataset(\n",
        "    url='https://drive.google.com/file/d/1idKFDkAHJGAFDn1OyXZxsTbOSBx9GS8N/view?usp=sharing',\n",
        "    filename='BSD400.zip'\n",
        "    ):\n",
        "    if os.path.isfile(filename):\n",
        "        print(f'{filename} already exists. Skipping downloading.')\n",
        "        return\n",
        "\n",
        "    with urllib.request.urlopen(url) as downloaded_file, open(filename, 'wb') as f:\n",
        "        f.write(downloaded_file.read())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNv-tETsssvL",
        "outputId": "fc87a153-74e8-4698-c998-0faad074f874"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "##Extraction\n",
        "\n",
        "def extract_datazip(\n",
        "    path_src='BSD400.zip',\n",
        "    path_dest='BSD400'\n",
        "):\n",
        "    with ZipFile(path_src, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "        return True\n",
        "\n",
        "extract_datazip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-vGTwUNfvLxW"
      },
      "outputs": [],
      "source": [
        "###On deplace les images dans un dossier\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def move_files_to_train_folder():\n",
        "\n",
        "  source_folder = './BSD400'\n",
        "  destination_folder = './BDS400/real'\n",
        "\n",
        "  if not os.path.exists(destination_folder):\n",
        "      os.makedirs(destination_folder)\n",
        "\n",
        "  for filename in os.listdir(source_folder):\n",
        "      source_file = os.path.join(source_folder, filename)\n",
        "      destination_file = os.path.join(destination_folder, filename)\n",
        "      shutil.move(source_file, destination_file)\n",
        "\n",
        "move_files_to_train_folder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nCUwd36cu7D0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "def load_images(path, img_size=(128, 128)):\n",
        "    images = []\n",
        "    for filename in os.listdir(path):\n",
        "        img = cv2.imread(os.path.join(path, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, img_size)\n",
        "            img = img / 255.0  # Normalize to [0, 1]\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "TRAIN_DIR = \"./BDS400/real\"\n",
        "train_images = load_images(TRAIN_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Swm1gkYNFe-T"
      },
      "outputs": [],
      "source": [
        "def add_gaussian_noise(images, mean=0, sigma=0.1):\n",
        "    noise = np.random.normal(mean, sigma, images.shape)\n",
        "    noisy_images = np.clip(images + noise, 0, 1)\n",
        "    return noisy_images\n",
        "\n",
        "train_noisy_images = add_gaussian_noise(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KKRKQu0Ez4Z",
        "outputId": "750793fc-4e4d-4fac-d0c3-6ba6884ad959"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(train_images),len(train_noisy_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mAGFuElKFHJ4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HrcnXZ0983op",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6adad672-a420-4e6a-d48c-716638ff242f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    CustomDataset(train_noisy_images, train_images),\n",
        "    batch_size=64,\n",
        "    num_workers=4,\n",
        "    shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs5lNl8YhlQo",
        "outputId": "c0220621-699f-4bfe-b1d3-adc0f7de6aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 128, 128, 3])\n",
            "torch.Size([64, 128, 128, 3])\n",
            "torch.Size([64, 3, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "for noisy_images, clean_images in train_dataloader:\n",
        "  print(noisy_images.shape)\n",
        "  print(clean_images.shape)\n",
        "  X_train = noisy_images.permute(0, 3, 1, 2)\n",
        "  print(X_train.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFp6sHkb-Mob"
      },
      "source": [
        "## SCUNET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##fonction pour calcuer le psnr\n",
        "\n",
        "\n",
        "def calculate_psnr(img1, img2, border=0):\n",
        "    # img1 and img2 have range [0, 255]\n",
        "    #img1 = img1.squeeze()\n",
        "    #img2 = img2.squeeze()\n",
        "    if not img1.shape == img2.shape:\n",
        "        raise ValueError('Input images must have the same dimensions.')\n",
        "    h, w = img1.shape[:2]\n",
        "    img1 = img1[border:h-border, border:w-border]\n",
        "    img2 = img2[border:h-border, border:w-border]\n",
        "\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * math.log10(255.0 / math.sqrt(mse))\n",
        "\n",
        "\n",
        "def calculate_cost(model, dataloader, device):\n",
        "\n",
        "  model.eval()\n",
        "  total_psnr = 0\n",
        "  with torch.no_grad():\n",
        "    for noisy_images, clean_images in dataloader:\n",
        "      noisy_images = noisy_images.to(device)\n",
        "      clean_images = clean_images.to(device)\n",
        "\n",
        "      denoised_images = model(noisy_images)\n",
        "\n",
        "      for i in range(denoised_images.shape[0]):\n",
        "        denoised_img = denoised_images[i].cpu().numpy().transpose(1, 2, 0)\n",
        "        clean_img = clean_images[i].cpu().numpy().transpose(1, 2, 0)\n",
        "        total_psnr += calculate_psnr(denoised_img, clean_img)\n",
        "\n",
        "  average_psnr = total_psnr / len(dataloader.dataset)\n",
        "  return average_psnr\n"
      ],
      "metadata": {
        "id": "hhKcMMzqDJch"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGj1laqrjcBc",
        "outputId": "6d6357a3-f3cb-4803-e386-f92714f2ea0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "torch.Size([7, 3, 64, 128])\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from thop import profile\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from timm.models.layers import trunc_normal_, DropPath\n",
        "\n",
        "\n",
        "class WMSA(nn.Module):\n",
        "    \"\"\" Self-attention module in Swin Transformer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, head_dim, window_size, type):\n",
        "        super(WMSA, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.head_dim = head_dim\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.n_heads = input_dim//head_dim\n",
        "        self.window_size = window_size\n",
        "        self.type=type\n",
        "        self.embedding_layer = nn.Linear(self.input_dim, 3*self.input_dim, bias=True)\n",
        "\n",
        "        # TODO recover\n",
        "        # self.relative_position_params = nn.Parameter(torch.zeros(self.n_heads, 2 * window_size - 1, 2 * window_size -1))\n",
        "        self.relative_position_params = nn.Parameter(torch.zeros((2 * window_size - 1)*(2 * window_size -1), self.n_heads))\n",
        "\n",
        "        self.linear = nn.Linear(self.input_dim, self.output_dim)\n",
        "\n",
        "        trunc_normal_(self.relative_position_params, std=.02)\n",
        "        self.relative_position_params = torch.nn.Parameter(self.relative_position_params.view(2*window_size-1, 2*window_size-1, self.n_heads).transpose(1,2).transpose(0,1))\n",
        "\n",
        "    def generate_mask(self, h, w, p, shift):\n",
        "        \"\"\" generating the mask of SW-MSA\n",
        "        Args:\n",
        "            shift: shift parameters in CyclicShift.\n",
        "        Returns:\n",
        "            attn_mask: should be (1 1 w p p),\n",
        "        \"\"\"\n",
        "        # supporting sqaure.\n",
        "        attn_mask = torch.zeros(h, w, p, p, p, p, dtype=torch.bool, device=self.relative_position_params.device)\n",
        "        if self.type == 'W':\n",
        "            return attn_mask\n",
        "\n",
        "        s = p - shift\n",
        "        attn_mask[-1, :, :s, :, s:, :] = True\n",
        "        attn_mask[-1, :, s:, :, :s, :] = True\n",
        "        attn_mask[:, -1, :, :s, :, s:] = True\n",
        "        attn_mask[:, -1, :, s:, :, :s] = True\n",
        "        attn_mask = rearrange(attn_mask, 'w1 w2 p1 p2 p3 p4 -> 1 1 (w1 w2) (p1 p2) (p3 p4)')\n",
        "        return attn_mask\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Forward pass of Window Multi-head Self-attention module.\n",
        "        Args:\n",
        "            x: input tensor with shape of [b h w c];\n",
        "            attn_mask: attention mask, fill -inf where the value is True;\n",
        "        Returns:\n",
        "            output: tensor shape [b h w c]\n",
        "        \"\"\"\n",
        "        if self.type!='W': x = torch.roll(x, shifts=(-(self.window_size//2), -(self.window_size//2)), dims=(1,2))\n",
        "        x = rearrange(x, 'b (w1 p1) (w2 p2) c -> b w1 w2 p1 p2 c', p1=self.window_size, p2=self.window_size)\n",
        "        h_windows = x.size(1)\n",
        "        w_windows = x.size(2)\n",
        "        # sqaure validation\n",
        "        # assert h_windows == w_windows\n",
        "\n",
        "        x = rearrange(x, 'b w1 w2 p1 p2 c -> b (w1 w2) (p1 p2) c', p1=self.window_size, p2=self.window_size)\n",
        "        qkv = self.embedding_layer(x)\n",
        "        q, k, v = rearrange(qkv, 'b nw np (threeh c) -> threeh b nw np c', c=self.head_dim).chunk(3, dim=0)\n",
        "        sim = torch.einsum('hbwpc,hbwqc->hbwpq', q, k) * self.scale\n",
        "        # Adding learnable relative embedding\n",
        "        sim = sim + rearrange(self.relative_embedding(), 'h p q -> h 1 1 p q')\n",
        "        # Using Attn Mask to distinguish different subwindows.\n",
        "        if self.type != 'W':\n",
        "            attn_mask = self.generate_mask(h_windows, w_windows, self.window_size, shift=self.window_size//2)\n",
        "            sim = sim.masked_fill_(attn_mask, float(\"-inf\"))\n",
        "\n",
        "        probs = nn.functional.softmax(sim, dim=-1)\n",
        "        output = torch.einsum('hbwij,hbwjc->hbwic', probs, v)\n",
        "        output = rearrange(output, 'h b w p c -> b w p (h c)')\n",
        "        output = self.linear(output)\n",
        "        output = rearrange(output, 'b (w1 w2) (p1 p2) c -> b (w1 p1) (w2 p2) c', w1=h_windows, p1=self.window_size)\n",
        "\n",
        "        if self.type!='W': output = torch.roll(output, shifts=(self.window_size//2, self.window_size//2), dims=(1,2))\n",
        "        return output\n",
        "\n",
        "    def relative_embedding(self):\n",
        "        cord = torch.tensor(np.array([[i, j] for i in range(self.window_size) for j in range(self.window_size)]))\n",
        "        relation = cord[:, None, :] - cord[None, :, :] + self.window_size -1\n",
        "        # negative is allowed\n",
        "        return self.relative_position_params[:, relation[:,:,0].long(), relation[:,:,1].long()]\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, head_dim, window_size, drop_path, type='W', input_resolution=None):\n",
        "        \"\"\" SwinTransformer Block\n",
        "        \"\"\"\n",
        "        super(Block, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        assert type in ['W', 'SW']\n",
        "        self.type = type\n",
        "        if input_resolution <= window_size:\n",
        "            self.type = 'W'\n",
        "\n",
        "        print(\"Block Initial Type: {}, drop_path_rate:{:.6f}\".format(self.type, drop_path))\n",
        "        self.ln1 = nn.LayerNorm(input_dim)\n",
        "        self.msa = WMSA(input_dim, input_dim, head_dim, window_size, self.type)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.ln2 = nn.LayerNorm(input_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, 4 * input_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * input_dim, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.msa(self.ln1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.ln2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvTransBlock(nn.Module):\n",
        "    def __init__(self, conv_dim, trans_dim, head_dim, window_size, drop_path, type='W', input_resolution=None):\n",
        "        \"\"\" SwinTransformer and Conv Block\n",
        "        \"\"\"\n",
        "        super(ConvTransBlock, self).__init__()\n",
        "        self.conv_dim = conv_dim\n",
        "        self.trans_dim = trans_dim\n",
        "        self.head_dim = head_dim\n",
        "        self.window_size = window_size\n",
        "        self.drop_path = drop_path\n",
        "        self.type = type\n",
        "        self.input_resolution = input_resolution\n",
        "\n",
        "        assert self.type in ['W', 'SW']\n",
        "        if self.input_resolution <= self.window_size:\n",
        "            self.type = 'W'\n",
        "\n",
        "        self.trans_block = Block(self.trans_dim, self.trans_dim, self.head_dim, self.window_size, self.drop_path, self.type, self.input_resolution)\n",
        "        self.conv1_1 = nn.Conv2d(self.conv_dim+self.trans_dim, self.conv_dim+self.trans_dim, 1, 1, 0, bias=True)\n",
        "        self.conv1_2 = nn.Conv2d(self.conv_dim+self.trans_dim, self.conv_dim+self.trans_dim, 1, 1, 0, bias=True)\n",
        "\n",
        "        self.conv_block = nn.Sequential(\n",
        "                nn.Conv2d(self.conv_dim, self.conv_dim, 3, 1, 1, bias=False),\n",
        "                nn.ReLU(True),\n",
        "                nn.Conv2d(self.conv_dim, self.conv_dim, 3, 1, 1, bias=False)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_x, trans_x = torch.split(self.conv1_1(x), (self.conv_dim, self.trans_dim), dim=1)\n",
        "        conv_x = self.conv_block(conv_x) + conv_x\n",
        "        trans_x = Rearrange('b c h w -> b h w c')(trans_x)\n",
        "        trans_x = self.trans_block(trans_x)\n",
        "        trans_x = Rearrange('b h w c -> b c h w')(trans_x)\n",
        "        res = self.conv1_2(torch.cat((conv_x, trans_x), dim=1))\n",
        "        x = x + res\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class SCUNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_nc=3, config=[2,2,2,2,2,2,2], dim=64, drop_path_rate=0.0, input_resolution=256):\n",
        "        super(SCUNet, self).__init__()\n",
        "        self.config = config\n",
        "        self.dim = dim\n",
        "        self.head_dim = 32\n",
        "        self.window_size = 8\n",
        "\n",
        "        # drop path rate for each layer\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(config))]\n",
        "\n",
        "        self.m_head = [nn.Conv2d(in_nc, dim, 3, 1, 1, bias=False)]\n",
        "\n",
        "        begin = 0\n",
        "        self.m_down1 = [ConvTransBlock(dim//2, dim//2, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution)\n",
        "                      for i in range(config[0])] + \\\n",
        "                      [nn.Conv2d(dim, 2*dim, 2, 2, 0, bias=False)]\n",
        "\n",
        "        begin += config[0]\n",
        "        self.m_down2 = [ConvTransBlock(dim, dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution//2)\n",
        "                      for i in range(config[1])] + \\\n",
        "                      [nn.Conv2d(2*dim, 4*dim, 2, 2, 0, bias=False)]\n",
        "\n",
        "        begin += config[1]\n",
        "        self.m_down3 = [ConvTransBlock(2*dim, 2*dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW',input_resolution//4)\n",
        "                      for i in range(config[2])] + \\\n",
        "                      [nn.Conv2d(4*dim, 8*dim, 2, 2, 0, bias=False)]\n",
        "\n",
        "        begin += config[2]\n",
        "        self.m_body = [ConvTransBlock(4*dim, 4*dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution//8)\n",
        "                    for i in range(config[3])]\n",
        "\n",
        "        begin += config[3]\n",
        "        self.m_up3 = [nn.ConvTranspose2d(8*dim, 4*dim, 2, 2, 0, bias=False),] + \\\n",
        "                      [ConvTransBlock(2*dim, 2*dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW',input_resolution//4)\n",
        "                      for i in range(config[4])]\n",
        "\n",
        "        begin += config[4]\n",
        "        self.m_up2 = [nn.ConvTranspose2d(4*dim, 2*dim, 2, 2, 0, bias=False),] + \\\n",
        "                      [ConvTransBlock(dim, dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution//2)\n",
        "                      for i in range(config[5])]\n",
        "\n",
        "        begin += config[5]\n",
        "        self.m_up1 = [nn.ConvTranspose2d(2*dim, dim, 2, 2, 0, bias=False),] + \\\n",
        "                    [ConvTransBlock(dim//2, dim//2, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution)\n",
        "                      for i in range(config[6])]\n",
        "\n",
        "        self.m_tail = [nn.Conv2d(dim, in_nc, 3, 1, 1, bias=False)]\n",
        "\n",
        "        self.m_head = nn.Sequential(*self.m_head)\n",
        "        self.m_down1 = nn.Sequential(*self.m_down1)\n",
        "        self.m_down2 = nn.Sequential(*self.m_down2)\n",
        "        self.m_down3 = nn.Sequential(*self.m_down3)\n",
        "        self.m_body = nn.Sequential(*self.m_body)\n",
        "        self.m_up3 = nn.Sequential(*self.m_up3)\n",
        "        self.m_up2 = nn.Sequential(*self.m_up2)\n",
        "        self.m_up1 = nn.Sequential(*self.m_up1)\n",
        "        self.m_tail = nn.Sequential(*self.m_tail)\n",
        "        #self.apply(self._init_weights)\n",
        "\n",
        "    def forward(self, x0):\n",
        "\n",
        "        h, w = x0.size()[-2:]\n",
        "        paddingBottom = int(np.ceil(h/64)*64-h)\n",
        "        paddingRight = int(np.ceil(w/64)*64-w)\n",
        "        x0 = nn.ReplicationPad2d((0, paddingRight, 0, paddingBottom))(x0)\n",
        "\n",
        "        x1 = self.m_head(x0)\n",
        "        x2 = self.m_down1(x1)\n",
        "        x3 = self.m_down2(x2)\n",
        "        x4 = self.m_down3(x3)\n",
        "        x = self.m_body(x4)\n",
        "        x = self.m_up3(x+x4)\n",
        "        x = self.m_up2(x+x3)\n",
        "        x = self.m_up1(x+x2)\n",
        "        x = self.m_tail(x+x1)\n",
        "\n",
        "        x = x[..., :h, :w]\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # torch.cuda.empty_cache()\n",
        "    net = SCUNet()\n",
        "\n",
        "    x = torch.randn((7, 3, 64, 128))\n",
        "    x = net(x)\n",
        "    print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aEDViKLrQEZ",
        "outputId": "f17a88c9-32f5-4406-f3e9-4bae43d8b0a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suppression des dossiers cachés dans le dossier :\n"
          ]
        }
      ],
      "source": [
        "###Supprimer checkpoint\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Spécifiez le chemin du dossier que vous souhaitez explorer\n",
        "directory_path = './BSD400'  # Remplacez par le chemin de votre dossier\n",
        "\n",
        "# Lister les fichiers et dossiers du dossier\n",
        "files = os.listdir(directory_path)\n",
        "\n",
        "# Supprimer uniquement les dossiers cachés\n",
        "print(\"Suppression des dossiers cachés dans le dossier :\")\n",
        "for file in files:\n",
        "    file_path = os.path.join(directory_path, file)\n",
        "\n",
        "    # Vérifier si c'est un dossier caché (commence par un point)\n",
        "    if file.startswith('.') and os.path.isdir(file_path):\n",
        "        shutil.rmtree(file_path)  # Supprimer le dossier et son contenu\n",
        "        print(f\"Dossier supprimé : {file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taj_J3oL-Xql",
        "outputId": "e0007402-366b-4078-feb0-6ccfb0a69c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "torch.float32\n",
            "torch.float32\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Fonction d'entraînement sans evaluer sur le val\n",
        "\n",
        "\n",
        "def train_scunet(model, dataloader, epochs=10, lr=0.001, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    #criterion = calculate_cost()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for noisy_imgs, clean_imgs in dataloader:\n",
        "          noisy_imgs=noisy_imgs.float()\n",
        "          clean_imgs=clean_imgs.float()\n",
        "          print(noisy_imgs.dtype)\n",
        "          print(clean_imgs.dtype)\n",
        "\n",
        "          noisy_imgs, clean_imgs = noisy_imgs.to(device), clean_imgs.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          #noisy_imgs=noisy_imgs.double()\n",
        "          noisy_imgs = noisy_imgs.permute(0, 3, 1, 2)\n",
        "          clean_imgs = clean_imgs.permute(0, 3, 1, 2)\n",
        "\n",
        "          outputs = model(noisy_imgs)\n",
        "          loss = criterion(outputs, clean_imgs)\n",
        "          #loss=criterion(model,dataloader,device)\n",
        "\n",
        "          # Backward pass\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader):.4f}\")\n",
        "\n",
        "# Initialiser et entraîner le modèle\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SCUNet()\n",
        "train_scunet(model, train_dataloader, epochs=10, lr=0.001, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIY3IDIcgJp1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Utilser cette fonction si il y a un val set\n",
        "\"\"\"\n",
        "\n",
        "def train_1epoch(dataloader, model, loss_fn, optimizer, device):\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    # Set the model to training mode.\n",
        "    # It is important for layers behaving differently between\n",
        "    # training and evaluation, such as batch normalization and dropout layers.\n",
        "    # Unnecessary in this situation but added for the best practice.\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)  # Model and data must be on the same device!\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Display loss from time to time\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss: >7f}  [{current: >5d} / {size: >5d}]\")\n",
        "\n",
        "\n",
        "def evaluate(dataloader, model, loss_fn, device, set_='Validation'):\n",
        "    # Set the model to evaluation mode.\n",
        "    # It is important for layers behaving differently between\n",
        "    # training and evaluation, such as batch normalization and dropout layers.\n",
        "    # Unnecessary in this situation but added for the best practice.\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # Move the tensors to `device`. For instance, it could be a GPU.\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"\\n{set_} set: \")  # \\n means \"new line\"\n",
        "    print(f\" Aaccuracy: {(100 * correct): >0.1f}%,\"\n",
        "          f\" Avg loss: {test_loss: >8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQJUH_rbhGmL",
        "outputId": "e4a501e5-ce56-4d3f-a967-86873e1f3428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Using cpu device\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SCUNet(\n",
              "  (m_head): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (m_down1): Sequential(\n",
              "    (0): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=32, out_features=96, bias=True)\n",
              "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=32, out_features=96, bias=True)\n",
              "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "  )\n",
              "  (m_down2): Sequential(\n",
              "    (0): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=64, out_features=192, bias=True)\n",
              "          (linear): Linear(in_features=64, out_features=64, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=64, out_features=192, bias=True)\n",
              "          (linear): Linear(in_features=64, out_features=64, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "  )\n",
              "  (m_down3): Sequential(\n",
              "    (0): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=128, out_features=384, bias=True)\n",
              "          (linear): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=128, out_features=384, bias=True)\n",
              "          (linear): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "  )\n",
              "  (m_body): Sequential(\n",
              "    (0): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=256, out_features=768, bias=True)\n",
              "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=256, out_features=768, bias=True)\n",
              "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (m_up3): Sequential(\n",
              "    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "    (1): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=128, out_features=384, bias=True)\n",
              "          (linear): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=128, out_features=384, bias=True)\n",
              "          (linear): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (m_up2): Sequential(\n",
              "    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "    (1): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=64, out_features=192, bias=True)\n",
              "          (linear): Linear(in_features=64, out_features=64, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=64, out_features=192, bias=True)\n",
              "          (linear): Linear(in_features=64, out_features=64, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (m_up1): Sequential(\n",
              "    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "    (1): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=32, out_features=96, bias=True)\n",
              "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): ConvTransBlock(\n",
              "      (trans_block): Block(\n",
              "        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (msa): WMSA(\n",
              "          (embedding_layer): Linear(in_features=32, out_features=96, bias=True)\n",
              "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv1_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (m_tail): Sequential(\n",
              "    (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_rate = 1e-3\n",
        "model = SCUNet()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn_mean = nn.CrossEntropyLoss(reduction='mean')  # for training\n",
        "loss_fn_sum = nn.CrossEntropyLoss(reduction='sum')  # for evaluation\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "model.to(device)  # `to` methods changes the state for torch.nn.Module.\n",
        "                  # We do not need to reassign the variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CJfYU7lpAAK"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
        "    train_1epoch(train_dataloader, model, loss_fn_mean, optimizer, device)\n",
        "    #evaluate(validation_dataloader, model, loss_fn_sum, device)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvLoEHQwvmIs"
      },
      "source": [
        "### CHARGEMENT MODELE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-oclSBBvmIs"
      },
      "outputs": [],
      "source": [
        "model = SCUNet()\n",
        "model.load_state_dict(torch.load('model_weights_epoch_10.pth', map_location=torch.device('cpu')))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model =model.double()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tegGYy4fvmIs",
        "outputId": "7256bd21-af08-4d5d-a182-8fe134ea709f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.Size([64, 3, 128, 128])\n",
            "torch.float64\n",
            "torch.Size([64, 3, 128, 128])\n",
            "torch.float64\n",
            "torch.Size([64, 3, 128, 128])\n",
            "torch.float64\n",
            "torch.Size([64, 3, 128, 128])\n",
            "torch.float64\n",
            "torch.Size([64, 3, 128, 128])\n",
            "torch.float64\n",
            "torch.Size([64, 3, 128, 128])\n",
            "torch.float64\n",
            "torch.Size([16, 3, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "elemdata=[]\n",
        "for noisy_images, clean_images in train_dataloader:\n",
        "    noisy_images=noisy_images.permute(0, 3, 1, 2)\n",
        "    noisy_images=noisy_images.double()\n",
        "    clean_images=clean_images.double()\n",
        "    clean_images=clean_images.permute(0, 3, 1, 2)\n",
        "    elemdata.append((noisy_images))\n",
        "    print(noisy_images.dtype)\n",
        "    print(clean_images.shape)\n",
        "    #break\n",
        "len(elemdata)\n",
        "\n",
        "def denormalize_images(images):\n",
        "    return images * 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cGgL1ssvmIt"
      },
      "outputs": [],
      "source": [
        "###Execute uniquement ceci pour l'instant\n",
        "\n",
        "for noisy_images in elemdata:\n",
        "    noisy_images = noisy_images.to(device)\n",
        "    outputs = model(noisy_images)\n",
        "    outputs = outputs.to('cuda')\n",
        "    outputs = denormalize_images(outputs)\n",
        "    outputs = outputs.detach().numpy()\n",
        "    outputs = outputs.astype(np.uint8)\n",
        "    outputs = np.transpose(outputs, (0, 2, 3, 1))\n",
        "    for i in range(outputs.shape[0]):\n",
        "        plt.imshow(outputs[i])\n",
        "        plt.show()\n",
        "        psnr=calculate_psnr(outputs[i],clean_images[i])\n",
        "        print(psnr)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oysJ5EBYvmIt"
      },
      "outputs": [],
      "source": [
        "#model.eval()  # Passer en mode évaluation\n",
        "\n",
        "img_noisy_tensor = test[0].to(device)  # Déplacer l'image bruitée sur le bon appareil\n",
        "model.double()\n",
        "with torch.no_grad():\n",
        "    print(img_noisy_tensor.dtype)\n",
        "    #img_noisy_tensor = test[0].to(device).double()\n",
        "    #img_noisy_tensor = img_noisy_tensor.permute(2, 0, 1).unsqueeze(0)\n",
        "    denoised_image = model(img_noisy_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjFrOAeDvmIt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_denoising(model, dataloader, device='cpu'):\n",
        "    model.eval()\n",
        "    noisy_imgs, clean_imgs = next(iter(dataloader))\n",
        "    noisy_imgs=noisy_imgs.permute(0, 3, 1, 2)\n",
        "    clean_imgs=clean_imgs.permute(0, 3, 1, 2)\n",
        "\n",
        "    noisy_imgs, clean_imgs = noisy_imgs.to(device), clean_imgs.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        denoised_imgs = model(noisy_imgs)\n",
        "\n",
        "    # Affichage\n",
        "    fig, axs = plt.subplots(3, 5, figsize=(15, 9))\n",
        "    for i in range(5):\n",
        "        axs[0, i].imshow(noisy_imgs[i].cpu().squeeze(), cmap='gray')\n",
        "        axs[0, i].set_title(\"Noisy\")\n",
        "        axs[1, i].imshow(denoised_imgs[i].cpu().squeeze(), cmap='gray')\n",
        "        axs[1, i].set_title(\"Denoised\")\n",
        "        axs[2, i].imshow(clean_imgs[i].cpu().squeeze(), cmap='gray')\n",
        "        axs[2, i].set_title(\"Clean\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualiser\n",
        "model.double()\n",
        "visualize_denoising(model, train_dataloader, device=device)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}